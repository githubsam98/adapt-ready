##1.Data set reference link: https://www.consumerfinance.gov/data-
research/consumer-complaints/#download-the-data File data source: https://files.consumerfinance.gov/ccdb/complaints.csv.zip Problem statement: Download the data from the file data source and provide possible data insights.

[ ]
import zipfile
import os
import pandas as pd
import matplotlib.pyplot as plt

[ ]
zip_file_path = "/content/complaints2.json.zip"
[ ]
extracted_csv_path = "/content/extracted2_csv_files" #/content/extracted_csv_files
[ ]
os.makedirs(extracted_csv_path,exist_ok= True )
[ ]
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_csv_path)

Appolozige for the inconvience . The dataset which you have provide is corrupted. i have tried both csv & json file .

2. Given an unsorted array of integers, find the length of the longest continuous increasing subsequence (subarray).
Example 1:

Input:

[1,3,5,4,7]

Output: 3

[ ]
#function for finding longest continuous subsequence
def find_longcon(x):
  max_len = 1
  current_len = 1
  for i in range(1,len(x)):
    if x[i] > x[i-1]:
      current_len+=1
    else:
      max_len = max(max_len,current_len)
      current_len = 1

  return max_len #return the maximum no of continuous sequence

x = list(map(int,input("Enter a list of interger with space:").split())) #getting an user input as unsorted list of interger
print(find_longcon(x))

Enter a list of interger with space:1 3 5 4 7
3
3.Given a list of non negative integers, arrange them such that they form the largest number.
 Example 1:

 Input: [10,2]

 Output: "210"

 Example 2:

 Input: [3,30,34,5,9]

 Output: "9534330"

[ ]
def find_large(nums):
  nums_str = list(map(str,nums))
  nums_str.sort(key = lambda x : x*10 , reverse = True)
  largest_num = ("".join(nums_str))
  return largest_num

nums = list(map(int,input("Enter a list of interger with space:").split()))
print(find_large(nums))
Enter a list of interger with space:3 60 5 9 7 1
9760531
4. Store all the "servlet-name", and "servlet-class" to a csv file from the attached sample_json.json file using Python.
[ ]
#importing requierd liabrary
import pandas as pd
import json
from google.colab import files
[ ]
#Read the json file
data = pd.read_json("/content/DT A1 sample_json (1) (1) (3).json")
[ ]
data

[ ]
#Extract the servlets details
servlets = data["web-app"]["servlet"]
servlets
[{'servlet-name': 'cofaxCDS',
  'servlet-class': 'org.cofax.cds.CDSServlet',
  'init-param': {'configGlossary:installationAt': 'Philadelphia, PA',
   'configGlossary:adminEmail': 'ksm@pobox.com',
   'configGlossary:poweredBy': 'Cofax',
   'configGlossary:poweredByIcon': '/images/cofax.gif',
   'configGlossary:staticPath': '/content/static',
   'templateProcessorClass': 'org.cofax.WysiwygTemplate',
   'templateLoaderClass': 'org.cofax.FilesTemplateLoader',
   'templatePath': 'templates',
   'templateOverridePath': '',
   'defaultListTemplate': 'listTemplate.htm',
   'defaultFileTemplate': 'articleTemplate.htm',
   'useJSP': 'false',
   'jspListTemplate': 'listTemplate.jsp',
   'jspFileTemplate': 'articleTemplate.jsp',
   'cachePackageTagsTrack': 200,
   'cachePackageTagsStore': 200,
   'cachePackageTagsRefresh': 60,
   'cacheTemplatesTrack': 100,
   'cacheTemplatesStore': 50,
   'cacheTemplatesRefresh': 15,
   'cachePagesTrack': 200,
   'cachePagesStore': 100,
   'cachePagesRefresh': 10,
   'cachePagesDirtyRead': 10,
   'searchEngineListTemplate': 'forSearchEnginesList.htm',
   'searchEngineFileTemplate': 'forSearchEngines.htm',
   'searchEngineRobotsDb': 'WEB-INF/robots.db',
   'useDataStore': 'true',
   'dataStoreClass': 'org.cofax.SqlDataStore',
   'redirectionClass': 'org.cofax.SqlRedirection',
   'dataStoreName': 'cofax',
   'dataStoreDriver': 'com.microsoft.jdbc.sqlserver.SQLServerDriver',
   'dataStoreUrl': 'jdbc:microsoft:sqlserver://LOCALHOST:1433;DatabaseName=goon',
   'dataStoreUser': 'sa',
   'dataStorePassword': 'dataStoreTestQuery',
   'dataStoreTestQuery': "SET NOCOUNT ON;select test='test';",
   'dataStoreLogFile': '/usr/local/tomcat/logs/datastore.log',
   'dataStoreInitConns': 10,
   'dataStoreMaxConns': 100,
   'dataStoreConnUsageLimit': 100,
   'dataStoreLogLevel': 'debug',
   'maxUrlLength': 500}},
 {'servlet-name': 'cofaxEmail',
  'servlet-class': 'org.cofax.cds.EmailServlet',
  'init-param': {'mailHost': 'mail1', 'mailHostOverride': 'mail2'}},
 {'servlet-name': 'cofaxAdmin', 'servlet-class': 'org.cofax.cds.AdminServlet'},
 {'servlet-name': 'fileServlet', 'servlet-class': 'org.cofax.cds.FileServlet'},
 {'servlet-name': 'cofaxTools',
  'servlet-class': 'org.cofax.cms.CofaxToolsServlet',
  'init-param': {'templatePath': 'toolstemplates/',
   'log': 1,
   'logLocation': '/usr/local/tomcat/logs/CofaxTools.log',
   'logMaxSize': '',
   'dataLog': 1,
   'dataLogLocation': '/usr/local/tomcat/logs/dataLog.log',
   'dataLogMaxSize': '',
   'removePageCache': '/content/admin/remove?cache=pages&id=',
   'removeTemplateCache': '/content/admin/remove?cache=templates&id=',
   'fileTransferFolder': '/usr/local/tomcat/webapps/content/fileTransferFolder',
   'lookInContext': 1,
   'adminGroupID': 4,
   'betaServer': 'true'}}]
[ ]
#Create the list to store all servlet
servlets_info = []
for servlet in servlets:
  name = servlet.get("servlet-name")
  clazz =servlet.get("servlet-class")
  servlets_info.append({"servlets_name": name, "servlets_class": clazz})
[ ]
#make it into dataframe
dt = pd.DataFrame(servlets_info)
dt

[ ]
dt.describe()

[ ]
#Convert dataframe into csv file
dt.to_csv("Servlets.csv",index=False)
[ ]
